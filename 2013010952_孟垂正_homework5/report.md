#人工智能导论第5次作业报告
计45 孟垂正 2013010952

[TOC]

## 要求
使用朴素贝叶斯和支持向量机方法进行文本分类.

## 编程语言与环境
采用Python实现, 支持向量机使用的是[libSVM]提供的svm-train程序. 运行环境为Python2.7.11, Arch Linux.

## 朴素贝叶斯方法

### 原理
- 对于每个分类$c_i$, 在独立性假设下计算出现串$x_1x_2...x_n$的概率:
$$P(X=x_1x_2...x_n|C=c_i)=P(C=c_i)P(X_1=x_1|C=c_i)...P(X_n=x_n|C=c_i)$$
其中$P(C=c_i)=\dfrac{N_{c_i类文档数}}{N_{总文档数}}$. 使得计算结果最大的$c_i$即为所在类.
- 采用拉普拉斯平滑估计条件概率. $$P(X_i=x_i|C=C_i)=\dfrac{N_{x_i在c_i类文本中出现的总次数}+1}{N_{c_i类文本以词为单位计算的总长度}+N_{所有文本中出现的词汇种类数}}$$

### 实现
使用Python处理文本, 提取单词和计算. 实现过程中应注意将概率累乘改为取对数后求和以避免浮点数过小时得到0.同时样本进行随机置乱以保证均匀. 采用10折交叉验证.

### 使用方法
```bash
#settingfile中存储了文本类别及其路径, num of fold 设定n折交叉验证中的n.
python2 main.py <settingfile> <num of fold> 
```


### 结果

**第i个Patch** | **正确率** 
------------ | -------
1 | 94.87%
2 | 100.00%
3 | 97.44%
4 | 100.00%
5 | 92.30%
6 | 97.44%
7 | 100.00%
8 | 94.87%
9 | 94.87%
10 | 94.87%

平均值为96.67%.

## 支持向量机方法

### 原理
将tf-idf作为每个词的权重, 形成每个文章的特征向量. 利用非线性支持向量机求解.

#### tf-idf方法
记输入所有文本中的所有词语构成集合V.对于某文章p,V中各词均可按照以下算法得到其特征值. 对于文章p中的q号词语, $tf_{qp}=N_{q在p中出现的次数}$, $idf_q=\ln\dfrac{N_{文章总数}}{N_{出现过词语q的文章数}}$. $tf\_idf_{qp}=(1+\ln tf_{qp})idf_q$. 特别地, 当$tf_{qp}=0$时, $tf\_idf_{qp}=0$.
#### SVM进行分类
使用非线性SVM进行分类, 核函数选取高斯核.

### 实现
#### 特征向量生成
使用Python生成SVM输入特征向量并按照libSVM规定的形式存储. 将所有词汇建立词汇表, 对于每个文本, 存储其类别编号, 并按照词汇在词汇表中的顺序依次存储其tf-idf值. 保存的文件作为svm-train的输入.

#### SVM训练
使用libSVM的svm-train进行学习. 进行10折交叉验证.命令如下:
```bash
# -s 0: 多类分类, -t 2: 高斯核函数, -v 10: 10-fold交叉验证, inputfile: 输入数据
./svm-train -s 0 -t 2 -v 10 <inputfile>
```

### 使用方法
```bash
#settingfile中存储了文本类别及其路径, savedfile存储生成的输入数据, num of fold 设定n折交叉验证中的n.
python2 parser.py <settingfile> <savedfile> <num of fold>
```

### 结果
SVM分类的准确率为95.25%.


[libSVM]: http://www.csie.ntu.edu.tw/~cjlin/libsvm/ "libSVM"
